# -*- coding: utf-8 -*-
"""Flickering ROC Asli dar paper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KjA2XiQgOXjyBj4ZbFP_FLmp-CVhggP0
"""

import numpy as np
import random
import matplotlib.pyplot as plt
import pandas as pd

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.models import load_model

model = load_model('flickering_4000_time_series_10000.h5')

steps = 40000#62500
def ts_gen(index_model,mode):
  if index_model==1 and mode ==1: #############################################

    dt = 10**-2

    X = np.zeros(steps)
    c = 0
    d = 1.5
    b = 0.5

    x_star = (1/3)*(c + np.sqrt((c**2) + (3*(d-1))))
    y_star = -(x_star**3) + (c*x_star**2) + (d*x_star)

    b_final = x_star - y_star - 0.5

    delta_b = (b_final - b) / steps


    def x_dot(x, b):
        return b - x - x**3 + (c*x**2) + (d*x)

    X[0] = 1
    S = 0.4#0.5
    window_size = 1000
    # Generate the time series
    for i in range(0, steps-1):
        X[i+1] = X[i] + (x_dot(X[i], b)*dt) + (np.sqrt(dt)*S*random.gauss(0, 1))
        b = b + delta_b

    X_series = pd.Series(X)

    # Compute rolling variance with the same window size
    X_var = X_series.rolling(window=window_size, min_periods=1).var().fillna(0).values

    return X

  elif index_model==1 and mode == 0: ##########################################

    dt = 10**-2

    X = np.zeros(steps)
    c = 0
    d = 1.5
    b = 0.5  # constant b

    x_star = (1/3)*(c + np.sqrt((c**2) + (3*(d-1))))
    y_star = -(x_star**3) + (c*x_star**2) + (d*x_star)

    # b stays constant → no delta_b needed
    def x_dot(x, b):
        return b - x - x**3 + (c*x**2) + (d*x)

    X[0] = 1
    S_initial = 0.4
    S_max = 1.0  # choose peak value

    # Precompute S over time
    S_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant S_initial
    S_values[:one_third] = S_initial

    # Middle third: ramp up then down (triangle shape)
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            # Increase from initial to max
            S_values[one_third + i] = S_initial + (S_max - S_initial) * (i / (mid_steps // 2))
        else:
            # Decrease back to initial
            S_values[one_third + i] = S_max - (S_max - S_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant S_initial
    S_values[-one_third:] = S_initial

    # Simulation loop
    for i in range(steps - 1):
        S = S_values[i]
        X[i+1] = X[i] + (x_dot(X[i], b) * dt) + (np.sqrt(dt) * S * random.gauss(0, 1))

    # Convert to pandas Series
    X_series = pd.Series(X)

    # Rolling variance
    window_size = 1000
    X_var = X_series.rolling(window=window_size, min_periods=1).var().fillna(0).values
    t = np.linspace(0, 1, steps)
    X1 = X
    return X1

  elif index_model==2 and mode ==1: ###########################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0 # Starting value of alpha
    alpha_end = -1  # Ending value of alpha
    S = 1           # s parameter
    r = 2           # r parameter
    b = 2         # b parameter for the new term
    sigma = 0.45   # sigma (noise strength)
    P0 = 2        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (1 - np.exp(-b * P**2))


    alpha = alpha_start
    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha

    return P3

  elif index_model == 2 and mode ==0: ########################################

      # Number of steps
    dt = 1e-2      # Time step
    alpha = 0      # Keep alpha constant
    S = 1          # S parameter
    r = 2          # r parameter
    b = 2          # b parameter for the new term
    sigma_initial = 0.45  # Initial noise strength
    sigma_max = 1.0        # Peak noise strength
    P0 = 2                 # Initial value of P

    # Precompute sigma values over time
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant sigma_initial
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up to max, then ramp down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            # Increase from initial to max
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            # Decrease back to initial
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant sigma_initial
    sigma_values[-one_third:] = sigma_initial

    # Initialize array for P values
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift term (alpha is constant here)
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (1 - np.exp(-b * P**2))

    # Simulate the SDE using Euler–Maruyama
    for i in range(steps - 1):
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt) * random.gauss(0, 1)
    X2 = P3
    return X2

  elif index_model == 3 and mode ==1: #####################################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0.5 # Starting value of alpha
    alpha_end = -1 # Ending value of alpha
    S = 1         # s parameter
    r = 2          # r parameter
    sigma = 0.9  # sigma (noise strength)
    P0 = 3       # Initial value of P

    # Precompute alpha values decreasing linearly

    alpha_values = np.linspace(alpha_start, alpha_end, steps)


    # Initialize arrays
    P2 = np.zeros(steps)
    P2[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r):
        return alpha - S * P + (r * np.tanh(P))

    def diffusion(P, sigma):
        return sigma

    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        alpha = alpha_values[i]
        P2[i+1] = P2[i] + drift(P2[i], alpha, S, r) * dt + diffusion(P2[i], sigma) * dW


    return P2


  elif index_model == 3 and mode ==0: #####################################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha = 0.5     # Keep alpha constant
    S = 1           # s parameter
    r = 2           # r parameter
    sigma_initial = 0.9  # Initial noise strength
    sigma_max = 1.5       # Peak noise strength
    P0 = 3               # Initial value of P

    # Precompute sigma variation over time
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize array
    P2 = np.zeros(steps)
    P2[0] = P0

    # Drift term
    def drift(P, alpha, S, r):
        return alpha - S * P + (r * np.tanh(P))

    # Simulate Euler–Maruyama
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P2[i+1] = P2[i] + drift(P2[i], alpha, S, r) * dt + sigma * dW
    X3 = P2
    return X3


  elif index_model ==4 and mode == 1: ################################################################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 1 # Starting value of alpha
    alpha_end = -0.5 # Ending value of alpha
    S = 1           # s parameter
    r = 1.5           # r parameter
    b = 2         # b parameter for the new term
    sigma = 0.5   # sigma (noise strength)
    P0 = 2        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (P**6/(1+P**6))


    alpha = alpha_start
    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha

    return P3

  elif index_model ==4 and mode == 0: ################################################################################

      # Number of steps
    dt = 1e-2      # Time step
    alpha = 1      # Keep alpha constant (initial value)
    S = 1          # s parameter
    r = 1.5        # r parameter
    b = 2          # b parameter for the new term
    sigma_initial = 0.5  # Initial noise strength
    sigma_max = 1.0       # Peak noise strength
    P0 = 2               # Initial value of P

    # Create sigma variation pattern
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize array
    P3 = np.zeros(steps)
    P3[0] = P0

    # Drift term
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (P**6 / (1 + P**6))

    # Simulate SDE using Euler–Maruyama
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * dW
    X4 = P3
    return X4


  elif index_model ==5 and mode == 1: #########################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0 # Starting value of alpha
    alpha_end = -1 # Ending value of alpha
    S = 1           # s parameter
            # b parameter for the new term
    sigma = 0.3   # sigma (noise strength)
    P0 = 1        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S):
        return alpha - (S * P) + (1/(1+np.exp(-10*P)))


    alpha = alpha_start
    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha


    return P3

  elif index_model ==5 and mode == 0: #########################################
       # Number of steps
    dt = 1e-2       # Time step
    alpha = 0       # Keep alpha constant
    S = 1           # s parameter
    sigma_initial = 0.3   # Initial noise strength
    sigma_max = 0.8       # Peak noise strength
    P0 = 1                # Initial value of P

    # Create sigma variation pattern
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize array
    P3 = np.zeros(steps)
    P3[0] = P0

    # Drift term
    def drift(P, alpha, S):
        return alpha - (S * P) + (1 / (1 + np.exp(-10 * P)))

    # Simulate Euler–Maruyama
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S) * dt + sigma * dW
    X5 = P3
    return X5

  elif index_model ==6 and mode ==1:
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0.5 # Starting value of alpha
    alpha_end = -1 # Ending value of alpha
    S = 1           # s parameter
    r = 1
    b = 1       # b parameter for the new term
    sigma = 0.8   # sigma (noise strength)
    P0 = 2        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + (np.arctan(10*P))


    alpha = alpha_start

    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha

    return P3
  elif index_model ==6 and mode ==0:

       # Number of steps
    dt = 1e-2        # Time step
    alpha = 0.5      # Keep alpha constant
    S = 1            # s parameter
    r = 1
    b = 1
    sigma_initial = 0.8   # Initial noise strength
    sigma_max = 1.5        # Peak noise strength
    P0 = 2                 # Initial value of P

    # Create sigma variation pattern (triangle shape)
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Drift term
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + np.arctan(10 * P)

    # Simulate Euler–Maruyama method
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * dW
    X6 = P3
    return X6


steps_dl = 10000

def analysis(X3):

  import statsmodels.api as sm
  from scipy.ndimage import gaussian_filter1d
  from sklearn.preprocessing import StandardScaler
  from sklearn.decomposition import PCA
  from statsmodels.tsa.seasonal import seasonal_decompose
  steps2 = len(X3)

  intervals = 500#1000


  size = int(((steps2/steps_dl)-1)*intervals)+1
  Y = np.zeros((size,steps_dl,2))

  t = np.zeros(size)
  for i in range(0,size):
    j1=int(i*steps_dl/intervals)
    j2 = j1+steps_dl

    Y[i,:,0] = X3[j1:j2]
    Y[i,:,0] = (Y[i,:,0]-np.average(Y[i,:,0]))/(np.std(Y[i,:,0]))
    X_series = pd.Series(X3[j1:j2])
    window_size = 1000
    X_var = X_series.rolling(window=window_size, min_periods=1).var().fillna(0).values
    Y[i,:,1] = X_var
    Y[i,:,1] = (Y[i,:,1]-np.average(Y[i,:,1]))/(np.std(Y[i,:,1]))


  np.shape(Y)
  predict_x1=model.predict(Y)



  non_flicker_prob1 = predict_x1[:,0]
  flicker_prob1 = predict_x1[:,1]

  window_size = 400

  non_flicker_prob2 = np.convolve(non_flicker_prob1, np.ones(window_size)/window_size, mode='valid')
  flicker_prob2 = np.convolve(flicker_prob1, np.ones(window_size)/window_size, mode='valid')


  t = np.linspace(0, 1 - (steps_dl/steps2), len(non_flicker_prob2))
  return flicker_prob2
###############################


# def ROC_analysis(T, mean_probs):
#     roc = np.zeros(len(T))
#     for i, t in enumerate(T):  # use enumerate to get index i
#         if np.max(mean_probs) > t:
#             roc[i] = 1
#     return roc


def ROC_analysis(mean_probs):

    return np.max(mean_probs)-np.mean(mean_probs)
#

X_flicker = ts_gen(3, 0)
plt.plot(X_flicker)

plt.plot(analysis(X_flicker))

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

all_scores = []
all_labels = []
number_gather = 40

# Loop over all index_model types
for index_model in range(1, 7):
    for _ in range(number_gather):
        # Flickering case (label = 1)
        X_flicker = ts_gen(index_model, 1)
        score_flicker = ROC_analysis(analysis(X_flicker))
        all_scores.append(score_flicker)
        all_labels.append(1)

        # Null case (label = 0)
        X_null = ts_gen(index_model, 0)
        score_null = ROC_analysis(analysis(X_null))
        all_scores.append(score_null)
        all_labels.append(0)

# Convert to NumPy arrays
all_scores = np.array(all_scores)
all_labels = np.array(all_labels)

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(all_labels, all_scores)
auc_score = roc_auc_score(all_labels, all_scores)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.3f})', color='blue', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', linewidth=1)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Flickering Detection')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

num_models = 6
samples_per_model = 2 * number_gather  # 10 flickering + 10 null per model

fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for model_idx in range(num_models):
    start = model_idx * samples_per_model
    end = start + samples_per_model

    model_scores = all_scores[start:end]
    model_labels = all_labels[start:end]

    fpr, tpr, _ = roc_curve(model_labels, model_scores)
    auc = roc_auc_score(model_labels, model_scores)

    ax = axes[model_idx]
    ax.plot(fpr, tpr, label=f'AUC = {auc:.3f}', color='blue', linewidth=2)
    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)
    ax.set_title(f'Model {model_idx + 1}', fontsize=14)
    ax.set_xlabel('FPR')
    ax.set_ylabel('TPR')
    ax.legend(loc='lower right')
    ax.grid(True)

plt.suptitle("ROC Curves per Model", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

import numpy as np
from sklearn.metrics import roc_curve, roc_auc_score
from google.colab import files

# === Assuming all_scores and all_labels are still in memory ===
num_models = 6
samples_per_model = 2 * number_gather

fpr_list = []
tpr_list = []
auc_list = []

for model_idx in range(num_models):
    start = model_idx * samples_per_model
    end = start + samples_per_model

    model_scores = all_scores[start:end]
    model_labels = all_labels[start:end]

    fpr, tpr, _ = roc_curve(model_labels, model_scores)
    auc = roc_auc_score(model_labels, model_scores)

    fpr_list.append(fpr)
    tpr_list.append(tpr)
    auc_list.append(auc)

# Convert lists to object arrays before saving
fpr_arr = np.array(fpr_list, dtype=object)
tpr_arr = np.array(tpr_list, dtype=object)
auc_arr = np.array(auc_list)

# Save using allow_pickle=True
np.savez("roc_data_per_model.npz", fpr_list=fpr_arr, tpr_list=tpr_arr, auc_list=auc_arr)

# Download to your machine
files.download("roc_data_per_model.npz")

from google.colab import files
uploaded = files.upload()

data = np.load("roc_data_per_model (1) (1).npz", allow_pickle=True)
fpr_list = data["fpr_list"]
tpr_list = data["tpr_list"]
auc_list = data["auc_list"]

# Example usage
import matplotlib.pyplot as plt
plt.plot(fpr_list[0], tpr_list[0])
plt.title(f"Model 1 ROC (AUC = {auc_list[0]:.3f})")
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.grid(True)
plt.show()

steps = 40000#62500
import random
import numpy as np
import pandas as pd
def ts_gen(index_model,mode):
  if index_model==1 and mode ==1: #############################################

    dt = 10**-2

    X = np.zeros(steps)
    c = 0
    d = 1.5
    b = 0.5

    x_star = (1/3)*(c + np.sqrt((c**2) + (3*(d-1))))
    y_star = -(x_star**3) + (c*x_star**2) + (d*x_star)

    b_final = x_star - y_star - 0.5

    delta_b = (b_final - b) / steps


    def x_dot(x, b):
        return b - x - x**3 + (c*x**2) + (d*x)

    X[0] = 1
    S = 0.4#0.5
    window_size = 1000
    # Generate the time series
    for i in range(0, steps-1):
        X[i+1] = X[i] + (x_dot(X[i], b)*dt) + (np.sqrt(dt)*S*random.gauss(0, 1))
        b = b + delta_b

    X_series = pd.Series(X)

    # Compute rolling variance with the same window size
    X_var = X_series.rolling(window=window_size, min_periods=1).var().fillna(0).values

    return X

  elif index_model==1 and mode == 0: ##########################################

    dt = 10**-2

    X = np.zeros(steps)
    c = 0
    d = 1.5
    b = 0.5  # constant b

    x_star = (1/3)*(c + np.sqrt((c**2) + (3*(d-1))))
    y_star = -(x_star**3) + (c*x_star**2) + (d*x_star)

    # b stays constant → no delta_b needed
    def x_dot(x, b):
        return b - x - x**3 + (c*x**2) + (d*x)

    X[0] = 1
    S_initial = 0.4
    S_max = 1.0  # choose peak value

    # Precompute S over time
    S_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant S_initial
    S_values[:one_third] = S_initial

    # Middle third: ramp up then down (triangle shape)
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            # Increase from initial to max
            S_values[one_third + i] = S_initial + (S_max - S_initial) * (i / (mid_steps // 2))
        else:
            # Decrease back to initial
            S_values[one_third + i] = S_max - (S_max - S_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant S_initial
    S_values[-one_third:] = S_initial

    # Simulation loop
    for i in range(steps - 1):
        S = S_values[i]
        X[i+1] = X[i] + (x_dot(X[i], b) * dt) + (np.sqrt(dt) * S * random.gauss(0, 1))

    # Convert to pandas Series
    X_series = pd.Series(X)

    # Rolling variance
    window_size = 1000
    X_var = X_series.rolling(window=window_size, min_periods=1).var().fillna(0).values
    t = np.linspace(0, 1, steps)
    X1 = X
    return X1

  elif index_model==2 and mode ==1: ###########################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0 # Starting value of alpha
    alpha_end = -1  # Ending value of alpha
    S = 1           # s parameter
    r = 2           # r parameter
    b = 2         # b parameter for the new term
    sigma = 0.45   # sigma (noise strength)
    P0 = 2        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (1 - np.exp(-b * P**2))


    alpha = alpha_start
    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha

    return P3

  elif index_model == 2 and mode ==0: ########################################

      # Number of steps
    dt = 1e-2      # Time step
    alpha = 0      # Keep alpha constant
    S = 1          # S parameter
    r = 2          # r parameter
    b = 2          # b parameter for the new term
    sigma_initial = 0.45  # Initial noise strength
    sigma_max = 1.0        # Peak noise strength
    P0 = 2                 # Initial value of P

    # Precompute sigma values over time
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant sigma_initial
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up to max, then ramp down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            # Increase from initial to max
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            # Decrease back to initial
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant sigma_initial
    sigma_values[-one_third:] = sigma_initial

    # Initialize array for P values
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift term (alpha is constant here)
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (1 - np.exp(-b * P**2))

    # Simulate the SDE using Euler–Maruyama
    for i in range(steps - 1):
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt) * random.gauss(0, 1)
    X2 = P3
    return X2

  elif index_model == 3 and mode ==1: #####################################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0.5 # Starting value of alpha
    alpha_end = -1 # Ending value of alpha
    S = 1         # s parameter
    r = 2          # r parameter
    sigma = 0.9  # sigma (noise strength)
    P0 = 3       # Initial value of P

    # Precompute alpha values decreasing linearly

    alpha_values = np.linspace(alpha_start, alpha_end, steps)


    # Initialize arrays
    P2 = np.zeros(steps)
    P2[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r):
        return alpha - S * P + (r * np.tanh(P))

    def diffusion(P, sigma):
        return sigma

    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        alpha = alpha_values[i]
        P2[i+1] = P2[i] + drift(P2[i], alpha, S, r) * dt + diffusion(P2[i], sigma) * dW


    return P2


  elif index_model == 3 and mode ==0: #####################################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha = 0.5     # Keep alpha constant
    S = 1           # s parameter
    r = 2           # r parameter
    sigma_initial = 0.9  # Initial noise strength
    sigma_max = 1.5       # Peak noise strength
    P0 = 3               # Initial value of P

    # Precompute sigma variation over time
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize array
    P2 = np.zeros(steps)
    P2[0] = P0

    # Drift term
    def drift(P, alpha, S, r):
        return alpha - S * P + (r * np.tanh(P))

    # Simulate Euler–Maruyama
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P2[i+1] = P2[i] + drift(P2[i], alpha, S, r) * dt + sigma * dW
    X3 = P2
    return X3


  elif index_model ==4 and mode == 1: ################################################################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 1 # Starting value of alpha
    alpha_end = -0.5 # Ending value of alpha
    S = 1           # s parameter
    r = 1.5           # r parameter
    b = 2         # b parameter for the new term
    sigma = 0.5   # sigma (noise strength)
    P0 = 2        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (P**6/(1+P**6))


    alpha = alpha_start
    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha

    return P3

  elif index_model ==4 and mode == 0: ################################################################################

      # Number of steps
    dt = 1e-2      # Time step
    alpha = 1      # Keep alpha constant (initial value)
    S = 1          # s parameter
    r = 1.5        # r parameter
    b = 2          # b parameter for the new term
    sigma_initial = 0.5  # Initial noise strength
    sigma_max = 1.0       # Peak noise strength
    P0 = 2               # Initial value of P

    # Create sigma variation pattern
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize array
    P3 = np.zeros(steps)
    P3[0] = P0

    # Drift term
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + r * (P**6 / (1 + P**6))

    # Simulate SDE using Euler–Maruyama
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * dW
    X4 = P3
    return X4


  elif index_model ==5 and mode == 1: #########################################
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0 # Starting value of alpha
    alpha_end = -1 # Ending value of alpha
    S = 1           # s parameter
            # b parameter for the new term
    sigma = 0.3   # sigma (noise strength)
    P0 = 1        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S):
        return alpha - (S * P) + (1/(1+np.exp(-10*P)))


    alpha = alpha_start
    # Simulate the SDE using Euler-Maruyama method
    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha


    return P3

  elif index_model ==5 and mode == 0: #########################################
       # Number of steps
    dt = 1e-2       # Time step
    alpha = 0       # Keep alpha constant
    S = 1           # s parameter
    sigma_initial = 0.3   # Initial noise strength
    sigma_max = 0.8       # Peak noise strength
    P0 = 1                # Initial value of P

    # Create sigma variation pattern
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize array
    P3 = np.zeros(steps)
    P3[0] = P0

    # Drift term
    def drift(P, alpha, S):
        return alpha - (S * P) + (1 / (1 + np.exp(-10 * P)))

    # Simulate Euler–Maruyama
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S) * dt + sigma * dW
    X5 = P3
    return X5

  elif index_model ==6 and mode ==1:
      # Number of steps
    dt = 1e-2       # Time step
    alpha_start = 0.5 # Starting value of alpha
    alpha_end = -1 # Ending value of alpha
    S = 1           # s parameter
    r = 1
    b = 1       # b parameter for the new term
    sigma = 0.8   # sigma (noise strength)
    P0 = 2        # Initial value of P

    # Precompute alpha values decreasing linearly
    alpha_values = np.linspace(alpha_start, alpha_end, steps)

    d_alpha = (alpha_end - alpha_start) / steps

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Define the drift and diffusion terms
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + (np.arctan(10*P))


    alpha = alpha_start

    for i in range(steps - 1):
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * np.sqrt(dt)*random.gauss(0, 1)
        alpha = alpha + d_alpha

    return P3
  elif index_model ==6 and mode ==0:

       # Number of steps
    dt = 1e-2        # Time step
    alpha = 0.5      # Keep alpha constant
    S = 1            # s parameter
    r = 1
    b = 1
    sigma_initial = 0.8   # Initial noise strength
    sigma_max = 1.5        # Peak noise strength
    P0 = 2                 # Initial value of P

    # Create sigma variation pattern (triangle shape)
    sigma_values = np.zeros(steps)
    one_third = steps // 3

    # First third: constant
    sigma_values[:one_third] = sigma_initial

    # Middle third: ramp up then down
    mid_steps = one_third
    for i in range(mid_steps):
        if i < mid_steps // 2:
            sigma_values[one_third + i] = sigma_initial + (sigma_max - sigma_initial) * (i / (mid_steps // 2))
        else:
            sigma_values[one_third + i] = sigma_max - (sigma_max - sigma_initial) * ((i - mid_steps // 2) / (mid_steps // 2))

    # Last third: constant
    sigma_values[-one_third:] = sigma_initial

    # Initialize arrays
    P3 = np.zeros(steps)
    P3[0] = P0

    # Drift term
    def drift(P, alpha, S, r, b):
        return alpha - (S * P) + np.arctan(10 * P)

    # Simulate Euler–Maruyama method
    for i in range(steps - 1):
        dW = np.sqrt(dt) * random.gauss(0, 1)  # Wiener increment
        sigma = sigma_values[i]
        P3[i + 1] = P3[i] + drift(P3[i], alpha, S, r, b) * dt + sigma * dW
    X6 = P3
    return X6

def variance_analysis(ts):
## Compute Rolling Variance
  ts_series = pd.Series(ts)
  window_size =   670#1000
  rolling_variance = ts_series.rolling(window=window_size, min_periods=1).var().fillna(0)
  return rolling_variance#(np.max(rolling_variance)/np.mean(rolling_variance))


def ROC_analysis(V):
    return np.max(V) / (np.mean(V)+np.std(V))



# def ROC_analysis(T, ratio):
#     roc = np.zeros(len(T))
#     for i, t in enumerate(T):  # use enumerate to get index i
#         if ratio > t:
#             roc[i] = 1
#     return roc

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

all_scores = []
all_labels = []
number_gather = 100

# Loop over all index_model types
for index_model in range(1, 7):
    for _ in range(number_gather):
        # Flickering case (label = 1)
        X_flicker = ts_gen(index_model, 1)
        score_flicker = ROC_analysis(variance_analysis(X_flicker))
        all_scores.append(score_flicker)
        all_labels.append(1)

        # Null case (label = 0)
        X_null = ts_gen(index_model, 0)
        score_null = ROC_analysis(variance_analysis(X_null))
        all_scores.append(score_null)
        all_labels.append(0)

# Convert to NumPy arrays
all_scores = np.array(all_scores)
all_labels = np.array(all_labels)

# Compute ROC curve and AUC
fpr, tpr, thresholds = roc_curve(all_labels, all_scores)
auc_score = roc_auc_score(all_labels, all_scores)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_score:.3f})', color='blue', linewidth=2)
plt.plot([0, 1], [0, 1], 'k--', linewidth=1)
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Flickering Detection')
plt.legend(loc='lower right')
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

num_models = 6
samples_per_model = 2 * number_gather  # 10 flickering + 10 null per model

fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for model_idx in range(num_models):
    start = model_idx * samples_per_model
    end = start + samples_per_model

    model_scores = all_scores[start:end]
    model_labels = all_labels[start:end]

    fpr, tpr, _ = roc_curve(model_labels, model_scores)
    auc = roc_auc_score(model_labels, model_scores)

    ax = axes[model_idx]
    ax.plot(fpr, tpr, label=f'AUC = {auc:.3f}', color='blue', linewidth=2)
    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)
    ax.set_title(f'Model {model_idx + 1}', fontsize=14)
    ax.set_xlabel('FPR')
    ax.set_ylabel('TPR')
    ax.legend(loc='lower right')
    ax.grid(True)

plt.suptitle("ROC Curves per Model", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

from google.colab import files
uploaded = files.upload()

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score
import numpy as np

# Load AI-based ROC data
data = np.load("roc_data_per_model (1).npz", allow_pickle=True)
fpr_list = data["fpr_list"]
tpr_list = data["tpr_list"]
auc_list = data["auc_list"]

# Settings
num_models = 6
samples_per_model = 2 * number_gather  # flickering + null per model

# Create subplots
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for model_idx in range(num_models):
    # ==== Variance-based ROC ====
    start = model_idx * samples_per_model
    end = start + samples_per_model

    model_scores = all_scores[start:end]
    model_labels = all_labels[start:end]

    fpr_var, tpr_var, _ = roc_curve(model_labels, model_scores)
    auc_var = roc_auc_score(model_labels, model_scores)

    # ==== AI-based ROC ====
    fpr_ai = fpr_list[model_idx]
    tpr_ai = tpr_list[model_idx]
    auc_ai = auc_list[model_idx]

    # ==== Plotting ====
    ax = axes[model_idx]
    ax.plot(fpr_var, tpr_var, label=f'Variance AUC = {auc_var:.3f}', color='blue', linewidth=2)
    ax.plot(fpr_ai, tpr_ai, label=f'DL AUC = {auc_ai:.3f}', color='orange', linewidth=2)
    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)

    ax.set_title(f'Model {model_idx + 1}', fontsize=14)
    ax.set_xlabel('FPR')
    ax.set_ylabel('TPR')
    ax.legend(loc='lower right')
    ax.grid(True)


# Final touches
plt.suptitle("Variance-Based vs DL-Based ROC Curves per Model", fontsize=16, fontweight='bold')
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig("roc_comparison.pdf", format='pdf', bbox_inches='tight')  # Save in current working directory
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score
import numpy as np

# Load AI-based ROC data
data = np.load("roc_data_per_model (1).npz", allow_pickle=True)
fpr_list = data["fpr_list"]
tpr_list = data["tpr_list"]
auc_list = data["auc_list"]

# Settings
num_models = 6
samples_per_model = 2 * number_gather  # flickering + null per model
subplot_labels = ['(A)', '(B)', '(C)', '(D)', '(E)', '(F)']

# Create subplots
fig, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for model_idx in range(num_models):
    # ==== Variance-based ROC ====
    start = model_idx * samples_per_model
    end = start + samples_per_model

    model_scores = all_scores[start:end]
    model_labels = all_labels[start:end]

    fpr_var, tpr_var, _ = roc_curve(model_labels, model_scores)
    auc_var = roc_auc_score(model_labels, model_scores)

    # ==== DL-based ROC ====
    fpr_ai = fpr_list[model_idx]
    tpr_ai = tpr_list[model_idx]
    auc_ai = auc_list[model_idx]

    # ==== Plotting ====
    ax = axes[model_idx]
    ax.plot(fpr_var, tpr_var, label=f'Variance AUC = {auc_var:.3f}', color='orange', linewidth=2)
    ax.plot(fpr_ai, tpr_ai, label=f'DL AUC = {auc_ai:.3f}', color='blue', linewidth=2)
    ax.plot([0, 1], [0, 1], 'k--', linewidth=1)

    ax.set_title(f'Model {model_idx + 1}', fontsize=14)
    ax.set_xlabel('FPR')
    ax.set_ylabel('TPR')
    ax.legend(loc='lower right')
    ax.grid(True)

    # Add subplot label (A), (B), ...
    ax.text(0.02, 1.1, subplot_labels[model_idx], transform=ax.transAxes,
            fontsize=14, fontweight='bold', va='top', ha='left')

# Final touches
plt.suptitle("Variance-Based vs DL-Based ROC Curves per Model", fontsize=16, fontweight='bold')
plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.savefig("roc_comparison.pdf", format='pdf', bbox_inches='tight')  # Save in current working directory
plt.show()

from google.colab import files
files.download("roc_comparison.pdf")